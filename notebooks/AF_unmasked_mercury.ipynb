{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29def768",
   "metadata": {
    "id": "29def768"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/clami66/AF_unmasked/blob/notebook/notebooks/AF_unmasked.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6KgI44cIYON",
   "metadata": {
    "id": "d6KgI44cIYON"
   },
   "source": [
    "# AF_unmasked: a simplified notebook\n",
    "\n",
    "<img src=\"https://github.com/clami66/AF_unmasked/raw/main/fig/header.png\" height=\"200\">\n",
    "\n",
    "This notebook allows to run AF_unmasked on multimeric sequences and templates of your choice. Not all features implemented on the command line version of AF_unmasked are currently available on the notebook, but more will come later.\n",
    "\n",
    "This version of AF_unmasked relies on MMseqs2 alignments, run by the [ColabFold](https://github.com/sokrypton/ColabFold) MSA server. Some of the code on this notebook is also based or taken from the ColabFold notebook.\n",
    "\n",
    "If you use this version of AF_unmasked in your research, consider citing:\n",
    "\n",
    "- Mirabello et al.: \"Unmasking AlphaFold to integrate experiments and predictions in multimeric complexes\". [Nature Communications volume 15, 8724 (2024)](https://www.nature.com/articles/s41467-024-52951-w)\n",
    "- Jumper et al.: \"Highly accurate protein structure prediction with AlphaFold\". [Nature volume 596, pages 583–589 (2021)](https://www.nature.com/articles/s41586-021-03819-2)\n",
    "- Evans et al.: \"Protein complex prediction with AlphaFold-Multimer\". [BiorXiv](https://www.biorxiv.org/content/early/2021/10/04/2021.10.04.463034)\n",
    "- Mirdita et al. \"ColabFold: making protein folding accessible to all\" [Nature Methods volume 19, pages 679–682 (2022)](https://www.nature.com/articles/s41592-022-01488-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fadb4d-4e38-4967-9e78-fb980eef13cf",
   "metadata": {
    "cellView": "form",
    "id": "64fadb4d-4e38-4967-9e78-fb980eef13cf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import shutil\n",
    "import importlib_metadata\n",
    "from pathlib import Path\n",
    "cwd = Path.cwd()\n",
    "from string import ascii_uppercase, ascii_lowercase\n",
    "ascii_upperlower = ascii_uppercase + ascii_lowercase\n",
    "\n",
    "python_version = f\"{sys.version_info.major}.{sys.version_info.minor}\"\n",
    "PYTHON_VERSION = python_version\n",
    "\n",
    "print(\"Setting up the environment...\")\n",
    "\n",
    "os.system(\"git clone -b notebook https://github.com/clami66/AF_unmasked.git\")\n",
    "\n",
    "if not os.path.isfile(\"COLABFOLD_READY\"):\n",
    "  print(\"installing colabfold...\")\n",
    "  os.system(\"pip install numpy<1.20 biopython==1.79 'colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold'\")\n",
    "  #os.system(\"ln -s /home/claudio/miniconda3/envs/mercury/lib/python3.10/site-packages/colabfold colabfold\")\n",
    "  #os.system(\"ln -s /home/claudio/miniconda3/envs/mercury/lib/python3.10/site-packages/alphafold alphafold\")\n",
    "  os.system(\"touch COLABFOLD_READY\")\n",
    "\n",
    "os.system(\"mamba install -y -c conda-forge -c bioconda hmmer kalign2=2.04 hhsuite=3.3.0\")\n",
    "sys.path.insert(0, f\"{cwd}/AF_unmasked\")\n",
    "sys.path.insert(0, f\"{cwd}\")\n",
    "\n",
    "import mercury as mr\n",
    "\n",
    "from AF_unmasked.alphafold.data.prepare_templates import *\n",
    "from AF_unmasked.alphafold.data.mmseqs_2_uniprot import *\n",
    "from Bio import Align, SeqIO, AlignIO\n",
    "from Bio.PDB.mmcifio import MMCIFIO\n",
    "\n",
    "from colabfold.batch import get_msa_and_templates, msa_to_str\n",
    "from colabfold.utils import DEFAULT_API_SERVER, get_commit\n",
    "from colabfold.download import download_alphafold_params\n",
    "\n",
    "from AF_unmasked.run_alphafold import predict_structure\n",
    "from AF_unmasked.alphafold.data import pipeline, pipeline_multimer\n",
    "\n",
    "from AF_unmasked.alphafold.data.tools import hmmsearch, jackhmmer\n",
    "from AF_unmasked.alphafold.data import templates\n",
    "\n",
    "from AF_unmasked.alphafold.model import model, data, config\n",
    "\n",
    "import py3Dmol\n",
    "import matplotlib.pyplot as plt\n",
    "from colabfold.colabfold import plot_plddt_legend\n",
    "from colabfold.colabfold import pymol_color_list, alphabet_list\n",
    "\n",
    "print(\"   ... done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b61f3-bfeb-414e-8962-fc1cb7855b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = mr.App(title=\"AF_unmasked\",\n",
    "        description=\"\",\n",
    "        show_code=False,\n",
    "        show_prompt=False,\n",
    "        continuous_update=True,\n",
    "        static_notebook=False,\n",
    "        show_sidebar=True,\n",
    "        full_screen=True,\n",
    "        allow_download=True,\n",
    "        allow_share=True,\n",
    "        stop_on_error=True\n",
    ")\n",
    "\n",
    "#mr.Markdown(text=\"\"\"### Job settings\n",
    "#\"\"\")\n",
    "\n",
    "jobname = mr.Text(value=\"\", label=\"Name your job:\", rows=1)\n",
    "if not jobname.value:\n",
    "    mr.Stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62d219-2628-421d-a646-05261cd67a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(f\"{jobname.value}\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "targets = out_dir.joinpath(f\"{jobname.value}.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0962e716-b4f4-4177-874f-5042ad413259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add file upload widget\n",
    "f = mr.File(label=\"Upload a single .fasta file for a multimeric target\", max_file_size=\"1MB\")\n",
    "fasta = f.filepath\n",
    "p = mr.File(label=\"Upload a template PDB (.pdb, .cif)\", max_file_size=\"20MB\")\n",
    "pdb = p.filepath\n",
    "\n",
    "if not fasta or not pdb:\n",
    "    mr.Stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62803f6f-4e3a-4823-98a1-a7fe24f1c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if p.filename.endswith(\".pdb\"):\n",
    "  template_format = \"pdb\"\n",
    "elif p.filename.endswith(\".cif\"):\n",
    "  template_format = \"cif\"\n",
    "else:\n",
    "  raise ValueError(\"Template must be in .pdb or .cif format\")\n",
    "\n",
    "fasta = Path(fasta)\n",
    "pdb = Path(pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe53b5e-e8a1-43b0-91c0-4a9c55e32499",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = shutil.copyfile(fasta, targets)\n",
    "\n",
    "if not is_fasta(targets):\n",
    "  raise ValueError(\"\"\"The input does not appear to be in fasta format\n",
    "  Example of fasta format input:\n",
    "  > H1142_A\n",
    "  GLEKDFLPLYFGWFLTK...\n",
    "  > H1142_B\n",
    "  EVQLEESGGGLVQAGGS...\n",
    "  \"\"\")\n",
    "\n",
    "with open(targets, \"r\") as f:\n",
    "  print(\"Fasta sequences:\")\n",
    "  print(f.read())\n",
    "  print()\n",
    "\n",
    "seq2chain = {}\n",
    "chain_idx = 0\n",
    "for record in SeqIO.parse(targets, \"fasta\"):\n",
    "  if record.seq not in seq2chain:\n",
    "    seq2chain[record.seq] = [ascii_upperlower[chain_idx]]\n",
    "  else:\n",
    "    seq2chain[record.seq].append(ascii_upperlower[chain_idx])\n",
    "  chain_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b0158a-3425-403b-8e49-4a61b99d9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = out_dir.joinpath(p.filename)\n",
    "_ = shutil.copyfile(pdb, template)\n",
    "\n",
    "# template data\n",
    "template_model = load_PDB(template, is_mmcif=(template_format == \"cif\"))\n",
    "template_chains = [c.id for c in template_model]\n",
    "remove_extra_chains(template_model, template_chains)\n",
    "remove_hetatms(template_model)\n",
    "template_sequences = [\n",
    "        get_fastaseq(template_model, chain) for chain in template_chains\n",
    "    ]\n",
    "\n",
    "print(\"Template sequences:\")\n",
    "for seq, chain in zip(template_sequences, template_chains):\n",
    "  print(f\"Chain {chain}: {seq}\")\n",
    "\n",
    "# target data\n",
    "target_chains, target_sequences, target_models = get_target_data(\n",
    "            [str(targets)],\n",
    "            chains=None,\n",
    "            is_fasta=True,\n",
    "            is_mmcif=False,\n",
    "        )\n",
    "assert len(target_chains) <= len(\n",
    "      template_chains\n",
    "), f\"Not enough chains in the template structure to cover all target chains. Partial templates are currently not supported on the colab version of AF_unmasked.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca11f0b3-fbec-4015-b89e-2b49b1d17e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = mr.Select(label=\"Select AF model type (v2 or v3)\",\n",
    "                          choices=[\"alphafold2_multimer_v2\", \"alphafold2_multimer_v3\"])\n",
    "\n",
    "predictions_per_model = mr.Numeric(value=1, min=1, max=10, label=\"Number of predictions per model:\", step=1)\n",
    "\n",
    "num_recycles = mr.Numeric(value=20, min=0, max=100, label=\"Number of recycles:\", step=1)\n",
    "recycle_early_stop_tolerance = mr.Numeric(value=0.5, min=0.0, max=1.0, label=\"Recycle early stop tolerance:\", step=1)\n",
    "use_dropout = mr.Checkbox(value=True, label=\"Use dropout to increase sampling noise:\")\n",
    "\n",
    "msa_mode = mr.Select(label=\"MSA mode:\", choices=[\"no_MSA\", \"mmseqs2_uniref\", \"mmseqs2_uniref_env\"])\n",
    "\n",
    "msa_depth = mr.Select(label=\"Number of sequences in MSA\",\n",
    "                          choices=[\"auto\", \"1\", \"32\", \"64\", \"256\", \"512\"])\n",
    "\n",
    "msa_depth = None if msa_depth.value == \"auto\" else int(msa_depth.value)\n",
    "\n",
    "inpaint_clashes = mr.Checkbox(value=True, label=\"Automatically inpaint clashes\")\n",
    "align = mr.Checkbox(value=True, label=\"Align template sequences to targets\")\n",
    "\n",
    "align_tool = \"blast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f79e2f5-a679-4c09-90d9-ed4fe92376b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_preview = [f\"Chain {template_chain} (seq: {template_seq[:10]}...)\" for template_chain, template_seq in zip(template_chains, template_sequences)]\n",
    "\n",
    "template_c = []\n",
    "for i, ch in enumerate(target_chains):\n",
    "    template_c.append(mr.Select(label=f\"Select template chain for fasta sequence {i+1} (seq: {target_sequences[i][:10]}\", value=template_preview[i], choices=template_preview, url_key=i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e06af2-b2eb-41e2-805b-89819a52de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pdb(pdb_file, extension, show_sidechains=False, show_mainchains=False, color=\"lDDT\"):\n",
    "  view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js',)\n",
    "  view.addModel(open(pdb_file,'r').read(), extension)\n",
    "\n",
    "  if color == \"lDDT\":\n",
    "    view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':50,'max':90}}})\n",
    "  elif color == \"rainbow\":\n",
    "    view.setStyle({'cartoon': {'color':'spectrum'}})\n",
    "  elif color == \"chain\":\n",
    "    chains = len(target_sequences) + 1\n",
    "    for n,chain,color in zip(range(chains),alphabet_list,pymol_color_list):\n",
    "       view.setStyle({'chain':chain},{'cartoon': {'color':color}})\n",
    "\n",
    "  if show_sidechains.value:\n",
    "    BB = ['C','O','N']\n",
    "    view.addStyle({'and':[{'resn':[\"GLY\",\"PRO\"],'invert':True},{'atom':BB,'invert':True}]},\n",
    "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
    "    view.addStyle({'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
    "                        {'sphere':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
    "    view.addStyle({'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
    "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
    "  if show_mainchains.value:\n",
    "    BB = ['C','O','N','CA']\n",
    "    view.addStyle({'atom':BB},{'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
    "\n",
    "  view.zoomTo()\n",
    "  return view\n",
    "\n",
    "repeat_template = mr.Select(label=\"Repeat template:\", choices=[\"1 time\", \"2 times\", \"3 times\", \"4 times\"], value=\"1 time\")\n",
    "\n",
    "run_temp = mr.Button(label=\"Run AF_unmasked\")\n",
    "done = False\n",
    "if run_temp.clicked:\n",
    "    temp_reps = int(repeat_template.value.split()[0])\n",
    "    template_chains = [temp.value.split()[1] for temp in template_c]\n",
    "    \n",
    "    if len(template_chains) != len(set(template_chains)):\n",
    "      raise ValueError(\"Must select a different template chain for each fasta sequence\")\n",
    "    \n",
    "    append = False\n",
    "    \n",
    "    mmcif_path = Path(out_dir, \"template_data\", \"mmcif_files\")\n",
    "    mmcif_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for i in range(temp_reps):\n",
    "        print(f\"Filling template slot n. {i+1}...\")\n",
    "        next_id = get_next_id(mmcif_path) if append else \"0000\"\n",
    "    \n",
    "        io = MMCIFIO()\n",
    "        template_mmcif_path = os.path.join(\n",
    "            out_dir, \"template_data\", \"mmcif_files\", f\"{next_id}.cif\"\n",
    "        )\n",
    "    \n",
    "        if inpaint_clashes:\n",
    "            template_model = detect_and_remove_clashes(template_model)\n",
    "            template_sequences = [\n",
    "                get_fastaseq(template_model, chain) for chain in template_chains\n",
    "            ]\n",
    "    \n",
    "        io.set_structure(template_model)\n",
    "        io.save(template_mmcif_path)\n",
    "    \n",
    "        fix_mmcif(\n",
    "            template_mmcif_path, template_chains, template_sequences, \"2100-01-01\"\n",
    "        )\n",
    "    \n",
    "        pdb_seqres_path = Path(out_dir, \"template_data\", \"pdb_seqres.txt\").resolve()\n",
    "        write_seqres(\n",
    "            pdb_seqres_path,\n",
    "            template_sequences,\n",
    "            template_chains,\n",
    "            seq_id=next_id,\n",
    "            append=append,\n",
    "        )\n",
    "    \n",
    "        # extra flagfile for AF usage\n",
    "        af_flagfile_path = Path(out_dir, \"template_data\", \"templates.flag\")\n",
    "        if not af_flagfile_path.is_file():  # don't overwrite file if already there\n",
    "            with open(af_flagfile_path, \"w\") as flagfile:\n",
    "                flagfile.write(f\"--template_mmcif_dir={mmcif_path.resolve()}\\n\")\n",
    "                flagfile.write(f\"--pdb_seqres_database_path={pdb_seqres_path}\\n\")\n",
    "                if align:  # means we are not going to let AF overwrite pdb_hits.sto\n",
    "                    flagfile.write(\"--use_precomputed_msas\\n\")\n",
    "    \n",
    "        if align:\n",
    "    \n",
    "            assert len(target_chains) == len(\n",
    "                template_chains\n",
    "            ), f\"The number of chains to align from target ({target_chains}) doesn't match the number of chains in the template ({template_chains}). Make sure that the files contain the same number of chains or select the chains that should be paired with --target_chains, --template_chains\"\n",
    "            for (\n",
    "                i,\n",
    "                (\n",
    "                    template_chain,\n",
    "                    template_sequence,\n",
    "                    target_chain,\n",
    "                    target_sequence,\n",
    "                    target_model,\n",
    "                ),\n",
    "            ) in enumerate(\n",
    "                zip(\n",
    "                    template_chains,\n",
    "                    template_sequences,\n",
    "                    target_chains,\n",
    "                    target_sequences,\n",
    "                    target_models,\n",
    "                )\n",
    "            ):\n",
    "                msa_chain = ascii_upperlower[i]\n",
    "                this_template_model = pickle.loads(pickle.dumps(template_model, -1))\n",
    "                this_target_model = pickle.loads(pickle.dumps(target_model, -1))\n",
    "                print(f\"Aligning fasta sequence {i+1} (seq: {target_sequence[0:10]}...) to template chain {template_chain} (seq: {template_sequence[0:10]}...)\")\n",
    "                alignment = do_align(\n",
    "                    template_sequence,\n",
    "                    this_template_model,\n",
    "                    target_sequence,\n",
    "                    this_target_model,\n",
    "                    alignment_type=\"blast\",\n",
    "                )\n",
    "                sto_alignment = format_alignment_stockholm(\n",
    "                    alignment, hit_id=next_id, hit_chain=template_chain\n",
    "                )\n",
    "    \n",
    "    \n",
    "                msa_path = f\"msas/{msa_chain}\"\n",
    "    \n",
    "                # write alignment to file\n",
    "                Path(out_dir, msa_path).mkdir(parents=True, exist_ok=True)\n",
    "                with open(\n",
    "                    Path(out_dir, msa_path, \"pdb_hits.sto\"),\n",
    "                    mode=\"a\" if append else \"w\",\n",
    "                ) as pdb_hits:\n",
    "                    for line in sto_alignment:\n",
    "                        pdb_hits.write(line)\n",
    "        if temp_reps > 1:\n",
    "            append = True\n",
    "        print(\"Predicting...\")\n",
    "\n",
    "    if msa_mode.value == \"no_MSA\": # same as \"no_MSA\" on the AF_unmasked paper\n",
    "      unpaired_msa = []\n",
    "      for i, ts in enumerate(target_sequences):\n",
    "        unpaired_msa.append(f\"> seq_{i}\\n{ts}\")\n",
    "      query_seqs_unique = set(target_sequences)\n",
    "    else: # Alignments rely on ColabFold's MSA server\n",
    "      print(\"Querying ColabFold's MSA server\")\n",
    "      msa_lines = None\n",
    "      use_templates = False\n",
    "      custom_template_path = None\n",
    "      pair_mode = \"unpaired\"\n",
    "      pairing_strategy = \"greedy\"\n",
    "      host_url = DEFAULT_API_SERVER\n",
    "      version = importlib_metadata.version(\"colabfold\")\n",
    "      commit = get_commit()\n",
    "      if commit:\n",
    "          version += f\" ({commit})\"\n",
    "      user_agent = f\"colabfold/{version}\"\n",
    "\n",
    "      unpaired_msa, paired_msa, query_seqs_unique, query_seqs_cardinality, template_features = get_msa_and_templates(jobname.value, target_sequences, msa_lines, out_dir, msa_mode, use_templates,\n",
    "                              custom_template_path, pair_mode, pairing_strategy, host_url, user_agent)\n",
    "\n",
    "    for sequence, msa in zip(query_seqs_unique, unpaired_msa):\n",
    "      chains = seq2chain[sequence]\n",
    "      for chain in chains:\n",
    "        out_dir.joinpath(f\"msas/{chain}/bfd_uniref_hits.a3m\").write_text(msa)\n",
    "        pseudo_uniprot = open(out_dir.joinpath(f\"msas/{chain}/uniprot_hits.a3m\"), \"w\")\n",
    "        pseudo_uniprot.write(f\"> {chain}\\n\")\n",
    "        pseudo_uniprot.write(str(sequence))\n",
    "        pseudo_uniprot.close()\n",
    "\n",
    "        input_handle  = open(out_dir.joinpath(f\"msas/{chain}/uniprot_hits.a3m\"), \"r\")\n",
    "        output_handle = open(out_dir.joinpath(f\"msas/{chain}/uniprot_hits.sto\"), \"w\")\n",
    "\n",
    "        alignments = AlignIO.parse(input_handle, \"fasta\")\n",
    "        AlignIO.write(alignments, output_handle, \"stockholm\")\n",
    "\n",
    "        output_handle.close()\n",
    "        input_handle.close()\n",
    "\n",
    "    data_dir = Path(\"./\")\n",
    "    if not glob.glob(f\"{data_dir}/params/*_finished.txt\"):\n",
    "      print(\"downloading AF parameters...\")\n",
    "      download_alphafold_params(model_type.value, data_dir)\n",
    "\n",
    "    template_searcher = hmmsearch.Hmmsearch(\n",
    "        binary_path=shutil.which(\"hmmsearch\"),\n",
    "        hmmbuild_binary_path=shutil.which(\"hmmbuild\"),\n",
    "        database_path=out_dir.joinpath(f\"template_data/pdb_seqres.txt\"))\n",
    "\n",
    "    template_featurizer = templates.HmmsearchHitFeaturizer(\n",
    "        mmcif_dir=mmcif_path.resolve(),\n",
    "        max_template_date=\"2100-01-01\",\n",
    "        max_hits=4,\n",
    "        kalign_binary_path=shutil.which(\"kalign\"),\n",
    "        release_dates_path=None,\n",
    "        obsolete_pdbs_path=None)\n",
    "\n",
    "    monomer_data_pipeline = pipeline.DataPipeline(\n",
    "        jackhmmer_binary_path=shutil.which(\"jackhmmer\"),\n",
    "        hhblits_binary_path=shutil.which(\"hhblits\"),\n",
    "        uniref90_database_path=\".\",\n",
    "        mgnify_database_path=\"\",\n",
    "        bfd_database_path=\"\",\n",
    "        uniref30_database_path=\"\",\n",
    "        small_bfd_database_path=\"\",\n",
    "        template_searcher=template_searcher,\n",
    "        template_featurizer=template_featurizer,\n",
    "        use_small_bfd=False,\n",
    "        use_precomputed_msas=True,\n",
    "        mgnify_max_hits=1,\n",
    "        uniref_max_hits=1,\n",
    "        bfd_max_hits=msa_depth,\n",
    "        no_uniref=True,\n",
    "        no_mgnify=True)\n",
    "\n",
    "    data_pipeline = pipeline_multimer.DataPipeline(\n",
    "        monomer_data_pipeline=monomer_data_pipeline,\n",
    "        jackhmmer_binary_path=shutil.which(\"jackhmmer\"),\n",
    "        uniprot_database_path=None,\n",
    "        use_precomputed_msas=True,\n",
    "        max_uniprot_hits=1,\n",
    "        separate_homomer_msas=True)\n",
    "\n",
    "    model_names = [\"model_5_multimer_v2\"] if model_type.value == \"alphafold2_multimer_v2\" else [\"model_5_multimer_v3\"]\n",
    "\n",
    "    model_runners = {}\n",
    "\n",
    "    for model_name in model_names:\n",
    "        model_config = config.model_config(model_name)\n",
    "        model_config.model.num_ensemble_eval = 1\n",
    "        model_config.model.embeddings_and_evoformer.cross_chain_templates = True\n",
    "        model_config.model.num_recycle = int(num_recycles.value)\n",
    "        model_config.model.global_config.eval_dropout = use_dropout.value\n",
    "        model_config.model.recycle_early_stop_tolerance = recycle_early_stop_tolerance.value\n",
    "\n",
    "        model_params = data.get_model_haiku_params(\n",
    "            model_name=model_name, data_dir=str(data_dir))\n",
    "        model_runner = model.RunModel(model_config, model_params)\n",
    "        for i in range(int(predictions_per_model.value)):\n",
    "          model_runners[f'{model_name}_pred_{i}'] = model_runner\n",
    "\n",
    "    predict_structure(\n",
    "        fasta_path=targets,\n",
    "        fasta_name=jobname.value,\n",
    "        output_dir_base=f\"{cwd}\",\n",
    "        data_pipeline=data_pipeline,\n",
    "        model_runners=model_runners,\n",
    "        benchmark=False,\n",
    "        random_seed=0,\n",
    "        models_to_relax=None)\n",
    "\n",
    "    done = True\n",
    "\n",
    "my_folder = mr.OutputDir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not done:\n",
    "    mr.Stop()\n",
    "\n",
    "rank_num = mr.Select(label=\"Select structure by rank\", choices=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], value=\"0\")\n",
    "color = mr.Select(label=\"Select structure coloring\", choices=[\"chain\", \"lDDT\", \"rainbow\"], value=\"chain\")\n",
    "show_sidechains = mr.Checkbox(value=False, label=\"Show sidechains\")\n",
    "show_mainchains = mr.Checkbox(value=False, label=\"Show mainchains\")\n",
    "\n",
    "prediction_pdb = f\"{out_dir}/ranked_{rank_num.value}.pdb\"\n",
    "template_pdb = f\"{mmcif_path}/0000.cif\"\n",
    "\n",
    "print(\"Template\")\n",
    "show_pdb(template_pdb, \"cif\", show_sidechains, show_mainchains, color).show()\n",
    "print(\"Prediction\")\n",
    "show_pdb(prediction_pdb, \"pdb\", show_sidechains, show_mainchains, color).show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
