{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AF_unmasked: a simplified notebook\n",
        "\n",
        "<img src=\"https://github.com/clami66/AF_unmasked/raw/main/fig/header.png\" height=\"200\">\n",
        "\n",
        "This notebook allows to run AF_unmasked on multimeric sequences and templates of your choice. Not all features implemented on the command line version of AF_unmasked are currently available on the notebook, but more will come later.\n",
        "\n",
        "This version of AF_unmasked relies on MMseqs2 alignments, run by the [ColabFold](https://github.com/sokrypton/ColabFold) MSA server. Some of the code on this notebook is also based on ColabFold.\n",
        "\n",
        "If you use this version of AF_unmasked in your research, please cite the articles under the \"References\" section below.\n"
      ],
      "metadata": {
        "id": "d6KgI44cIYON"
      },
      "id": "d6KgI44cIYON"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64fadb4d-4e38-4967-9e78-fb980eef13cf",
      "metadata": {
        "cellView": "form",
        "id": "64fadb4d-4e38-4967-9e78-fb980eef13cf"
      },
      "outputs": [],
      "source": [
        "#@title Step 1: Install dependencies\n",
        "import os\n",
        "from sys import version_info, path\n",
        "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
        "PYTHON_VERSION = python_version\n",
        "\n",
        "os.system(\"git clone -b notebook https://github.com/clami66/AF_unmasked.git\")\n",
        "\n",
        "if not os.path.isfile(\"COLABFOLD_READY\"):\n",
        "  print(\"installing colabfold...\")\n",
        "  os.system(\"pip install -q --no-warn-conflicts biopython==1.79 'colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold'\")\n",
        "  if os.environ.get('TPU_NAME', False) != False:\n",
        "    os.system(\"pip uninstall -y jax jaxlib\")\n",
        "    os.system(\"pip install --no-warn-conflicts --upgrade dm-haiku==0.0.10 'jax[cuda12_pip]'==0.3.25 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\")\n",
        "  os.system(\"touch COLABFOLD_READY\")\n",
        "\n",
        "\n",
        "if not os.path.isfile(\"CONDA_READY\"):\n",
        "  print(\"installing conda...\")\n",
        "  os.system(\"wget -qnc https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh\")\n",
        "  os.system(\"bash Mambaforge-Linux-x86_64.sh -bfp /usr/local\")\n",
        "  os.system(\"mamba config --set auto_update_conda false\")\n",
        "  os.system(\"touch CONDA_READY\")\n",
        "\n",
        "print(\"installing conda packages...\")\n",
        "!mamba install -y -c conda-forge -c bioconda hmmer kalign2=2.04 hhsuite=3.3.0 &> /dev/null\n",
        "\n",
        "path.insert(0,'/content/AF_unmasked')\n",
        "\n",
        "import pickle\n",
        "import shutil\n",
        "import importlib_metadata\n",
        "from pathlib import Path\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from google.colab import files\n",
        "\n",
        "from AF_unmasked.alphafold.data.prepare_templates import *\n",
        "from AF_unmasked.alphafold.data.mmseqs_2_uniprot import *\n",
        "from Bio import Align, SeqIO, AlignIO\n",
        "from Bio.PDB.mmcifio import MMCIFIO\n",
        "\n",
        "from colabfold.batch import get_msa_and_templates, msa_to_str\n",
        "from colabfold.utils import DEFAULT_API_SERVER, get_commit\n",
        "from colabfold.download import download_alphafold_params\n",
        "\n",
        "from AF_unmasked.run_alphafold import predict_structure\n",
        "from AF_unmasked.alphafold.data import pipeline, pipeline_multimer\n",
        "\n",
        "from AF_unmasked.alphafold.data.tools import hmmsearch, jackhmmer\n",
        "from AF_unmasked.alphafold.data import templates\n",
        "\n",
        "from AF_unmasked.alphafold.model import model, data, config\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 2: Input protein sequences\n",
        "jobname = \"H1142\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Only fasta inputs are accepted (see example below)\n",
        "#@markdown - Leave the fasta input as is to run example from AF_unmasked paper (H1142)\n",
        "fasta_input = widgets.Textarea(\n",
        "    value=\"\"\">H1142_A\n",
        "GLEKDFLPLYFGWFLTKKSSETLRKAGQVFLEELGNHKAFKKELRHFISGDEPKEKLELVSYFGKRPPGVLHCTTKFCDYKAAGAEEYAQQEVVKRSYGKAFKLSISALFVTPKTAGAQVVLTDQELQLWPSDLDKPSASEGLPPGSRAHVTLGCAADVQPVQTGLDLLDILQQVKGGSQGEAVGELPRGKLYSLGKGRWMLSLTKKMEVKAIFTGYYG\n",
        ">H1142_B\n",
        "EVQLEESGGGLVQAGGSLTLSCAASGFTFDDYAMGWYRQAPGKERVGVSCISRTDGYTYYLDSVKGRFTISTDHAKHTVYLQMNNLKPDDTGLYYCAADADPEYGSRCPDPYYGMDYWGKGILVTVSS\"\"\",\n",
        "    placeholder='Input protein sequences in fasta format',\n",
        "    description='Fasta input:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(height=\"200px\", width=\"auto\")\n",
        ")\n",
        "\n",
        "display(fasta_input)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221,
          "referenced_widgets": [
            "4ce2ccad8735492ba219042da3b594af",
            "d1f5ebbac43d4be9860662c9c032086e",
            "28a64395b26b4c568b480451a4a49d7c"
          ]
        },
        "cellView": "form",
        "id": "9NpApyzT4o8p",
        "outputId": "3d897fb6-20ff-4f5c-f1ba-76c202094b25"
      },
      "id": "9NpApyzT4o8p",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='>H1142_A\\nGLEKDFLPLYFGWFLTKKSSETLRKAGQVFLEELGNHKAFKKELRHFISGDEPKEKLELVSYFGKRPPGVLHCTTKFCDYKAAGâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ce2ccad8735492ba219042da3b594af"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 3: Upload template structure (.pdb or .cif)\n",
        "example_pdb = False #@param {type:\"boolean\"}\n",
        "#@markdown - Check box to use example from AF_unmasked paper (H1142.pdb)\n",
        "#@markdown - Otherwise, run this cell and click on the \"Browse\" button below to upload a template pdb\n",
        "\n",
        "out_dir = Path(f\"{jobname}\")\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "sequences = fasta_input.value\n",
        "\n",
        "targets = out_dir.joinpath(f\"{jobname}.fasta\")\n",
        "\n",
        "with open(targets, \"w\") as out:\n",
        "    out.write(sequences)\n",
        "\n",
        "if not example_pdb:\n",
        "  uploaded = files.upload()\n",
        "  pdb = Path(list(uploaded.keys())[0])\n",
        "else:\n",
        "  pdb = Path(\"/content/AF_unmasked/examples/H1142/H1142.pdb\")\n",
        "\n",
        "if pdb.name.endswith(\".pdb\"):\n",
        "  template_format = \"pdb\"\n",
        "elif pdb.name.endswith(\".cif\"):\n",
        "  template_format = \"cif\"\n",
        "else:\n",
        "  raise ValueError(\"Template must be in .pdb or .cif format\")\n",
        "\n",
        "template = out_dir.joinpath(pdb.name)\n",
        "_ = shutil.copyfile(pdb, template)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "60tEHBOI6-tn"
      },
      "id": "60tEHBOI6-tn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 4: Set other parameters\n",
        "model_type = \"alphafold2_multimer_v2\" #@param [\"alphafold2_multimer_v2\", \"alphafold2_multimer_v3\"]\n",
        "\n",
        "predictions_per_model = 1 #@param {type:\"integer\"}\n",
        "num_recycles = 3 #@param {type:\"integer\"}\n",
        "recycle_early_stop_tolerance = 0.5 #@param {type:\"number\"}\n",
        "use_dropout = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown #### MSA settings\n",
        "msa_mode = \"mmseqs2_uniref\" #@param [\"no_MSA\", \"mmseqs2_uniref\", \"mmseqs2_uniref_env\"]\n",
        "\n",
        "#@markdown -  decrease `msa_depth` to rely more on template information (min: 1)\n",
        "msa_depth = 10 #@param {type:\"integer\"}\n",
        "#@markdown - Pairing of MSAs is currently not allowed to enforce template contraints\n",
        "\n",
        "if msa_depth == \"auto\": msa_depth = None\n",
        "\n",
        "#@markdown Template options\n",
        "inpaint_clashes = True #@param {type:\"boolean\"}\n",
        "align = True #@param {type:\"boolean\"}\n",
        "superimpose = False #@param {type:\"boolean\"}\n",
        "align_tool = \"blast\"\n",
        "\n",
        "#@markdown #### Save settings\n",
        "save_to_google_drive = False #@param {type:\"boolean\"}\n",
        "\n",
        "if save_to_google_drive:\n",
        "  from pydrive2.drive import GoogleDrive\n",
        "  from pydrive2.auth import GoogleAuth\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  print(\"You are logged into Google Drive and are good to go!\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DO1X9PpZ18UJ"
      },
      "id": "DO1X9PpZ18UJ",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 5: provide mapping between target sequences and template chains\n",
        "\n",
        "# template data\n",
        "template_model = load_PDB(template, is_mmcif=(template_format == \"cif\"))\n",
        "template_chains = [c.id for c in template_model]\n",
        "remove_extra_chains(template_model, template_chains)\n",
        "remove_hetatms(template_model)\n",
        "template_sequences = [\n",
        "        get_fastaseq(template_model, chain) for chain in template_chains\n",
        "    ]\n",
        "\n",
        "# target data\n",
        "target_chains, target_sequences, target_models = get_target_data(\n",
        "            [str(targets)],\n",
        "            chains=None,\n",
        "            is_fasta=True,\n",
        "            is_mmcif=False,\n",
        "        )\n",
        "template_preview = [f\"Chain {template_chain} (seq: {template_seq[:10]}...)\" for template_chain, template_seq in zip(template_chains, template_sequences)]\n",
        "template_c = [widgets.Dropdown(options=template_preview, value=template_preview[i]) for i, ch in enumerate(target_chains)]\n",
        "\n",
        "for i, widget in enumerate(template_c):\n",
        "  print(f\"Select template chain for fasta sequence {i+1} (seq: {target_sequences[i][:10]}...)\")\n",
        "  display(widget)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sU_Zn7VgPhLP"
      },
      "id": "sU_Zn7VgPhLP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7678a19-f438-4752-87da-1257526ab1c9",
      "metadata": {
        "cellView": "form",
        "id": "e7678a19-f438-4752-87da-1257526ab1c9"
      },
      "outputs": [],
      "source": [
        "#@title Step 6: Perform sequence-template alignments and check the results\n",
        "#@markdown - Make sure to double check the alignments in the output to see that they are correct\n",
        "\n",
        "template_chains = [temp.value.split()[1] for temp in template_c]\n",
        "\n",
        "if len(template_chains) != len(set(template_chains)):\n",
        "  raise ValueError(\"Must select a different template chain for each fasta sequence\")\n",
        "\n",
        "append = False\n",
        "mmcif_path = Path(out_dir, \"template_data\", \"mmcif_files\")\n",
        "mmcif_path.mkdir(parents=True, exist_ok=True)\n",
        "next_id = get_next_id(mmcif_path) if append else \"0000\"\n",
        "\n",
        "io = MMCIFIO()\n",
        "template_mmcif_path = os.path.join(\n",
        "    out_dir, \"template_data\", \"mmcif_files\", f\"{next_id}.cif\"\n",
        ")\n",
        "\n",
        "if inpaint_clashes:\n",
        "    template_model = detect_and_remove_clashes(template_model)\n",
        "    template_sequences = [\n",
        "        get_fastaseq(template_model, chain) for chain in template_chains\n",
        "    ]\n",
        "\n",
        "io.set_structure(template_model)\n",
        "io.save(template_mmcif_path)\n",
        "\n",
        "fix_mmcif(\n",
        "    template_mmcif_path, template_chains, template_sequences, \"2100-01-01\"\n",
        ")\n",
        "\n",
        "pdb_seqres_path = Path(out_dir, \"template_data\", \"pdb_seqres.txt\").resolve()\n",
        "write_seqres(\n",
        "    pdb_seqres_path,\n",
        "    template_sequences,\n",
        "    template_chains,\n",
        "    seq_id=next_id,\n",
        "    append=append,\n",
        ")\n",
        "\n",
        "# extra flagfile for AF usage\n",
        "af_flagfile_path = Path(out_dir, \"template_data\", \"templates.flag\")\n",
        "if not af_flagfile_path.is_file():  # don't overwrite file if already there\n",
        "    with open(af_flagfile_path, \"w\") as flagfile:\n",
        "        flagfile.write(f\"--template_mmcif_dir={mmcif_path.resolve()}\\n\")\n",
        "        flagfile.write(f\"--pdb_seqres_database_path={pdb_seqres_path}\\n\")\n",
        "        if align:  # means we are not going to let AF overwrite pdb_hits.sto\n",
        "            flagfile.write(\"--use_precomputed_msas\\n\")\n",
        "\n",
        "if align:\n",
        "\n",
        "    assert len(target_chains) == len(\n",
        "        template_chains\n",
        "    ), f\"The number of chains to align from target ({target_chains}) doesn't match the number of chains in the template ({template_chains}). Make sure that the files contain the same number of chains or select the chains that should be paired with --target_chains, --template_chains\"\n",
        "    for (\n",
        "        i,\n",
        "        (\n",
        "            template_chain,\n",
        "            template_sequence,\n",
        "            target_chain,\n",
        "            target_sequence,\n",
        "            target_model,\n",
        "        ),\n",
        "    ) in enumerate(\n",
        "        zip(\n",
        "            template_chains,\n",
        "            template_sequences,\n",
        "            target_chains,\n",
        "            target_sequences,\n",
        "            target_models,\n",
        "        )\n",
        "    ):\n",
        "        msa_chain = ascii_upperlower[i]\n",
        "        this_template_model = pickle.loads(pickle.dumps(template_model, -1))\n",
        "        this_target_model = pickle.loads(pickle.dumps(target_model, -1))\n",
        "        print(f\"Aligning fasta sequence {i+1} (seq: {target_sequence[0:10]}...) to template chain {template_chain} (seq: {template_sequence[0:10]}...)\")\n",
        "        alignment = do_align(\n",
        "            template_sequence,\n",
        "            this_template_model,\n",
        "            target_sequence,\n",
        "            this_target_model,\n",
        "            alignment_type=\"blast\",\n",
        "        )\n",
        "        sto_alignment = format_alignment_stockholm(\n",
        "            alignment, hit_id=next_id, hit_chain=template_chain\n",
        "        )\n",
        "\n",
        "\n",
        "        msa_path = f\"msas/{msa_chain}\"\n",
        "\n",
        "        # write alignment to file\n",
        "        Path(out_dir, msa_path).mkdir(parents=True, exist_ok=True)\n",
        "        with open(\n",
        "            Path(out_dir, msa_path, \"pdb_hits.sto\"),\n",
        "            mode=\"a\" if append else \"w\",\n",
        "        ) as pdb_hits:\n",
        "            for line in sto_alignment:\n",
        "                pdb_hits.write(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d2a63c8-7e34-4f45-88aa-675355cf1818",
      "metadata": {
        "cellView": "form",
        "id": "5d2a63c8-7e34-4f45-88aa-675355cf1818"
      },
      "outputs": [],
      "source": [
        "#@title Step 7: Run the prediction with AF_unmasked\n",
        "\n",
        "if msa_mode == \"no_MSA\": # same as \"no_MSA\" on the AF_unmasked paper\n",
        "  unpaired_msa = []\n",
        "  for i, ts in enumerate(target_sequences):\n",
        "    unpaired_msa.append(f\"> seq_{i}\\n{ts}\")\n",
        "else: # Alignments rely on ColabFold's MSA server\n",
        "  print(\"Querying ColabFold's MSA server\")\n",
        "  msa_lines = None\n",
        "  use_templates = False\n",
        "  custom_template_path = None\n",
        "  pair_mode = \"unpaired\"\n",
        "  pairing_strategy = \"greedy\"\n",
        "  host_url = DEFAULT_API_SERVER\n",
        "  version = importlib_metadata.version(\"colabfold\")\n",
        "  commit = get_commit()\n",
        "  if commit:\n",
        "      version += f\" ({commit})\"\n",
        "  user_agent = f\"colabfold/{version}\"\n",
        "\n",
        "  unpaired_msa, paired_msa, query_seqs_unique, query_seqs_cardinality, template_features = get_msa_and_templates(jobname, target_sequences, msa_lines, out_dir, msa_mode, use_templates,\n",
        "                          custom_template_path, pair_mode, pairing_strategy, host_url, user_agent)\n",
        "\n",
        "for chain, sequence, msa in zip(target_chains, target_sequences, unpaired_msa):\n",
        "  out_dir.joinpath(f\"msas/{chain}/bfd_uniref_hits.a3m\").write_text(msa)\n",
        "  pseudo_uniprot = open(out_dir.joinpath(f\"msas/{chain}/uniprot_hits.a3m\"), \"w\")\n",
        "  pseudo_uniprot.write(f\"> {chain}\\n\")\n",
        "  pseudo_uniprot.write(str(sequence))\n",
        "  pseudo_uniprot.close()\n",
        "\n",
        "  input_handle  = open(out_dir.joinpath(f\"msas/{chain}/uniprot_hits.a3m\"), \"r\")\n",
        "  output_handle = open(out_dir.joinpath(f\"msas/{chain}/uniprot_hits.sto\"), \"w\")\n",
        "\n",
        "  alignments = AlignIO.parse(input_handle, \"fasta\")\n",
        "  AlignIO.write(alignments, output_handle, \"stockholm\")\n",
        "\n",
        "  output_handle.close()\n",
        "  input_handle.close()\n",
        "\n",
        "data_dir = Path(\"/content\")\n",
        "if not glob.glob(f\"{data_dir}/params/*_finished.txt\"):\n",
        "  print(\"downloading AF parameters...\")\n",
        "  download_alphafold_params(model_type, data_dir)\n",
        "\n",
        "template_searcher = hmmsearch.Hmmsearch(\n",
        "    binary_path=shutil.which(\"hmmsearch\"),\n",
        "    hmmbuild_binary_path=shutil.which(\"hmmbuild\"),\n",
        "    database_path=out_dir.joinpath(f\"template_data/pdb_seqres.txt\"))\n",
        "\n",
        "template_featurizer = templates.HmmsearchHitFeaturizer(\n",
        "    mmcif_dir=mmcif_path.resolve(),\n",
        "    max_template_date=\"2100-01-01\",\n",
        "    max_hits=4,\n",
        "    kalign_binary_path=shutil.which(\"kalign\"),\n",
        "    release_dates_path=None,\n",
        "    obsolete_pdbs_path=None)\n",
        "\n",
        "monomer_data_pipeline = pipeline.DataPipeline(\n",
        "      jackhmmer_binary_path=shutil.which(\"jackhmmer\"),\n",
        "      hhblits_binary_path=shutil.which(\"hhblits\"),\n",
        "      uniref90_database_path=\".\",\n",
        "      mgnify_database_path=\"\",\n",
        "      bfd_database_path=\"\",\n",
        "      uniref30_database_path=\"\",\n",
        "      small_bfd_database_path=\"\",\n",
        "      template_searcher=template_searcher,\n",
        "      template_featurizer=template_featurizer,\n",
        "      use_small_bfd=False,\n",
        "      use_precomputed_msas=True,\n",
        "      mgnify_max_hits=1,\n",
        "      uniref_max_hits=1,\n",
        "      bfd_max_hits=msa_depth,\n",
        "      no_uniref=True,\n",
        "      no_mgnify=True)\n",
        "\n",
        "data_pipeline = pipeline_multimer.DataPipeline(\n",
        "        monomer_data_pipeline=monomer_data_pipeline,\n",
        "        jackhmmer_binary_path=shutil.which(\"jackhmmer\"),\n",
        "        uniprot_database_path=None,\n",
        "        use_precomputed_msas=True,\n",
        "        max_uniprot_hits=1,\n",
        "        separate_homomer_msas=True)\n",
        "\n",
        "model_names = [\"model_1_multimer_v2\", \"model_5_multimer_v2\"] if model_type == \"alphafold2_multimer_v2\" else [\"model_1_multimer_v3\", \"model_5_multimer_v3\"]\n",
        "\n",
        "model_runners = {}\n",
        "\n",
        "for model_name in model_names:\n",
        "    model_config = config.model_config(model_name)\n",
        "    model_config.model.num_ensemble_eval = 1\n",
        "    model_config.model.embeddings_and_evoformer.cross_chain_templates = True\n",
        "    model_config.model.num_recycle = num_recycles\n",
        "    model_config.model.global_config.eval_dropout = use_dropout\n",
        "    model_config.model.recycle_early_stop_tolerance = recycle_early_stop_tolerance\n",
        "\n",
        "    model_params = data.get_model_haiku_params(\n",
        "        model_name=model_name, data_dir=str(data_dir))\n",
        "    model_runner = model.RunModel(model_config, model_params)\n",
        "    for i in range(predictions_per_model):\n",
        "      model_runners[f'{model_name}_pred_{i}'] = model_runner\n",
        "\n",
        "predict_structure(\n",
        "        fasta_path=targets,\n",
        "        fasta_name=jobname,\n",
        "        output_dir_base=\"/content\",\n",
        "        data_pipeline=data_pipeline,\n",
        "        model_runners=model_runners,\n",
        "        benchmark=False,\n",
        "        random_seed=0,\n",
        "        models_to_relax=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 8: Download results\n",
        "exclude_pickles = True #@param {type:\"boolean\"}\n",
        "extra_zip_flags = \"-x '*.pkl'\" if exclude_pickles else \"\"\n",
        "results_zip = f\"{jobname}_AF_unmasked.zip\"\n",
        "os.system(f\"zip {extra_zip_flags} -r {results_zip} {jobname}\")\n",
        "\n",
        "files.download(f\"{jobname}_AF_unmasked.zip\")\n",
        "if save_to_google_drive == True and drive:\n",
        "  uploaded = drive.CreateFile({'title': f\"{jobname}_AF_unmasked.zip\"})\n",
        "  uploaded.SetContentFile(f\"{jobname}_AF_unmasked.zip\")\n",
        "  uploaded.Upload()\n",
        "  print(f\"Uploaded {jobname}_AF_unmasked.zip to Google Drive with ID {uploaded.get('id')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "cellView": "form",
        "id": "eJt5jHOI39Am",
        "outputId": "23224deb-8b48-48ff-8766-14831973eeb4"
      },
      "id": "eJt5jHOI39Am",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_58e973e0-691e-4c6d-970d-115d49140efd\", \"H1142_AF_unmasked.zip\", 2245958)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title References\n",
        "\n",
        "\"\"\"\n",
        "@article{af_unmasked,\n",
        "  title={Unmasking AlphaFold: integration of experiments and predictions in multimeric complexes},\n",
        "  author={Mirabello, Claudio and Wallner, Bj{\\\"o}rn and Nystedt, Bj{\\\"o}rn and Azinas, Stavros and Carroni, Marta},\n",
        "  journal={bioRxiv},\n",
        "  pages={2023--09},\n",
        "  year={2023},\n",
        "  publisher={Cold Spring Harbor Laboratory}\n",
        "}\n",
        "\n",
        "@article{af2,\n",
        "  title={Highly accurate protein structure prediction with {AlphaFold}},\n",
        "  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\\v{Z}}{\\'\\i}dek, Augustin and Potapenko, Anna and others},\n",
        "  journal={Nature},\n",
        "  volume={596},\n",
        "  number={7873},\n",
        "  pages={583--589},\n",
        "  year={2021},\n",
        "  publisher={Nature Publishing Group UK London}\n",
        "}\n",
        "\n",
        "@article{af2_multimer,\n",
        "  title={Protein complex prediction with {AlphaFold-Multimer}},\n",
        "  author={Evans, Richard and Oâ€™Neill, Michael and Pritzel, Alexander and Antropova, Natasha and Senior, Andrew and Green, Tim and {\\v{Z}}{\\'\\i}dek, Augustin and Bates, Russ and Blackwell, Sam and Yim, Jason and others},\n",
        "  journal={BioRxiv},\n",
        "  pages={2021--10},\n",
        "  year={2021},\n",
        "  publisher={Cold Spring Harbor Laboratory}\n",
        "}\n",
        "\n",
        "@article{colabfold,\n",
        "  title={ColabFold: making protein folding accessible to all},\n",
        "  author={Mirdita, Milot and Sch{\\\"u}tze, Konstantin and Moriwaki, Yoshitaka and Heo, Lim and Ovchinnikov, Sergey and Steinegger, Martin},\n",
        "  journal={Nature methods},\n",
        "  volume={19},\n",
        "  number={6},\n",
        "  pages={679--682},\n",
        "  year={2022},\n",
        "  publisher={Nature Publishing Group US New York}\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "FeuGHFIYLifJ"
      },
      "id": "FeuGHFIYLifJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4ce2ccad8735492ba219042da3b594af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Fasta input:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_d1f5ebbac43d4be9860662c9c032086e",
            "placeholder": "Input protein sequences in fasta format",
            "rows": null,
            "style": "IPY_MODEL_28a64395b26b4c568b480451a4a49d7c",
            "value": ">H1142_A\nGLEKDFLPLYFGWFLTKKSSETLRKAGQVFLEELGNHKAFKKELRHFISGDEPKEKLELVSYFGKRPPGVLHCTTKFCDYKAAGAEEYAQQEVVKRSYGKAFKLSISALFVTPKTAGAQVVLTDQELQLWPSDLDKPSASEGLPPGSRAHVTLGCAADVQPVQTGLDLLDILQQVKGGSQGEAVGELPRGKLYSLGKGRWMLSLTKKMEVKAIFTGYYG\n>H1142_B\nEVQLEESGGGLVQAGGSLTLSCAASGFTFDDYAMGWYRQAPGKERVGVSCISRTDGYTYYLDSVKGRFTISTDHAKHTVYLQMNNLKPDDTGLYYCAADADPEYGSRCPDPYYGMDYWGKGILVTVSS"
          }
        },
        "d1f5ebbac43d4be9860662c9c032086e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "200px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "28a64395b26b4c568b480451a4a49d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}