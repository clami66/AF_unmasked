{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "29def768",
      "metadata": {
        "id": "29def768"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clami66/AF_unmasked/blob/notebook/notebooks/AF_unmasked.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6KgI44cIYON",
      "metadata": {
        "id": "d6KgI44cIYON"
      },
      "source": [
        "# AF_unmasked: a simplified notebook\n",
        "\n",
        "<img src=\"https://github.com/clami66/AF_unmasked/raw/main/fig/header.png\" height=\"200\">\n",
        "\n",
        "This notebook allows to run AF_unmasked on multimeric sequences and templates of your choice. Not all features implemented on the command line version of AF_unmasked are currently available on the notebook, but more will come later.\n",
        "\n",
        "This version of AF_unmasked relies on MMseqs2 alignments, run by the [ColabFold](https://github.com/sokrypton/ColabFold) MSA server. Some of the code on this notebook is also based or taken from the ColabFold notebook.\n",
        "\n",
        "If you use this version of AF_unmasked in your research, please cite the articles under the \"References\" section below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64fadb4d-4e38-4967-9e78-fb980eef13cf",
      "metadata": {
        "id": "64fadb4d-4e38-4967-9e78-fb980eef13cf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Step 1: Install dependencies\n",
        "import os\n",
        "from sys import version_info, path\n",
        "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
        "PYTHON_VERSION = python_version\n",
        "\n",
        "os.system(\"git clone -b notebook https://github.com/clami66/AF_unmasked.git\")\n",
        "\n",
        "if not os.path.isfile(\"COLABFOLD_READY\"):\n",
        "  print(\"installing colabfold...\")\n",
        "  os.system(\"pip install -q --no-warn-conflicts biopython==1.79 'colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold'\")\n",
        "  if os.environ.get('TPU_NAME', False) != False:\n",
        "    os.system(\"pip uninstall -y jax jaxlib\")\n",
        "    os.system(\"pip install --no-warn-conflicts --upgrade dm-haiku==0.0.10 'jax[cuda12_pip]'==0.3.25 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\")\n",
        "  os.system(\"touch COLABFOLD_READY\")\n",
        "\n",
        "\n",
        "if not os.path.isfile(\"CONDA_READY\"):\n",
        "  print(\"installing conda...\")\n",
        "  os.system(\"wget -qnc https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh\")\n",
        "  os.system(\"bash Mambaforge-Linux-x86_64.sh -bfp /usr/local\")\n",
        "  os.system(\"mamba config --set auto_update_conda false\")\n",
        "  os.system(\"touch CONDA_READY\")\n",
        "\n",
        "print(\"installing conda packages...\")\n",
        "!mamba install -y -c conda-forge -c bioconda hmmer kalign2=2.04 hhsuite=3.3.0 &> /dev/null\n",
        "\n",
        "path.insert(0,'/content/AF_unmasked')\n",
        "\n",
        "import pickle\n",
        "import shutil\n",
        "import importlib_metadata\n",
        "from pathlib import Path\n",
        "from string import ascii_uppercase, ascii_lowercase\n",
        "ascii_upperlower = ascii_uppercase + ascii_lowercase\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from google.colab import files\n",
        "\n",
        "from AF_unmasked.alphafold.data.prepare_templates import *\n",
        "from AF_unmasked.alphafold.data.mmseqs_2_uniprot import *\n",
        "from Bio import Align, SeqIO, AlignIO\n",
        "from Bio.PDB.mmcifio import MMCIFIO\n",
        "\n",
        "from colabfold.batch import get_msa_and_templates, msa_to_str\n",
        "from colabfold.utils import DEFAULT_API_SERVER, get_commit\n",
        "from colabfold.download import download_alphafold_params\n",
        "\n",
        "from AF_unmasked.run_alphafold import predict_structure\n",
        "from AF_unmasked.alphafold.data import pipeline, pipeline_multimer\n",
        "\n",
        "from AF_unmasked.alphafold.data.tools import hmmsearch, jackhmmer\n",
        "from AF_unmasked.alphafold.data import templates\n",
        "\n",
        "from AF_unmasked.alphafold.model import model, data, config\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 2: Upload input (.fasta) and a template (.pdb/.cif)\n",
        "jobname = \"test\" #@param {type:\"string\"}\n",
        "\n",
        "run_example = False #@param {type:\"boolean\"}\n",
        "#@markdown - Check box to use example from AF_unmasked paper (H1142.pdb)\n",
        "#@markdown - Otherwise, run this cell and upload a sequence input followed by a structural template\n",
        "out_dir = Path(f\"{jobname}\")\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "targets = out_dir.joinpath(f\"{jobname}.fasta\")\n",
        "\n",
        "if not run_example:\n",
        "  print(\"Upload the input sequences as a single fasta file\")\n",
        "  uploaded = files.upload()\n",
        "  fasta = Path(list(uploaded.keys())[0])\n",
        "else:\n",
        "  fasta = Path(\"/content/AF_unmasked/examples/H1142/H1142.fasta\")\n",
        "\n",
        "\n",
        "_ = shutil.copyfile(fasta, targets)\n",
        "\n",
        "if not is_fasta(targets):\n",
        "  raise ValueError(\"\"\"The input does not appear to be in fasta format\n",
        "  Example of fasta format input:\n",
        "  > H1142_A\n",
        "  GLEKDFLPLYFGWFLTK...\n",
        "  > H1142_B\n",
        "  EVQLEESGGGLVQAGGS...\n",
        "  \"\"\")\n",
        "\n",
        "with open(targets, \"r\") as f:\n",
        "  print(\"Fasta sequences:\")\n",
        "  print(f.read())\n",
        "  print()\n",
        "\n",
        "seq2chain = {}\n",
        "chain_idx = 0\n",
        "for record in SeqIO.parse(targets, \"fasta\"):\n",
        "  if record.seq not in seq2chain:\n",
        "    seq2chain[record.seq] = [ascii_upperlower[chain_idx]]\n",
        "  else:\n",
        "    seq2chain[record.seq].append(ascii_upperlower[chain_idx])\n",
        "  chain_idx += 1\n",
        "\n",
        "if not run_example:\n",
        "  print(\"Upload the template as a single PDB (or mmCIF) file\")\n",
        "  uploaded = files.upload()\n",
        "  pdb = Path(list(uploaded.keys())[0])\n",
        "else:\n",
        "  pdb = Path(\"/content/AF_unmasked/examples/H1142/H1142.pdb\")\n",
        "\n",
        "if pdb.name.endswith(\".pdb\"):\n",
        "  template_format = \"pdb\"\n",
        "elif pdb.name.endswith(\".cif\"):\n",
        "  template_format = \"cif\"\n",
        "else:\n",
        "  raise ValueError(\"Template must be in .pdb or .cif format\")\n",
        "\n",
        "template = out_dir.joinpath(pdb.name)\n",
        "_ = shutil.copyfile(pdb, template)\n",
        "\n",
        "# template data\n",
        "template_model = load_PDB(template, is_mmcif=(template_format == \"cif\"))\n",
        "template_chains = [c.id for c in template_model]\n",
        "remove_extra_chains(template_model, template_chains)\n",
        "remove_hetatms(template_model)\n",
        "template_sequences = [\n",
        "        get_fastaseq(template_model, chain) for chain in template_chains\n",
        "    ]\n",
        "\n",
        "print(\"Template sequences:\")\n",
        "for seq, chain in zip(template_sequences, template_chains):\n",
        "  print(f\"Chain {chain}: {seq}\")\n",
        "\n",
        "# target data\n",
        "target_chains, target_sequences, target_models = get_target_data(\n",
        "            [str(targets)],\n",
        "            chains=None,\n",
        "            is_fasta=True,\n",
        "            is_mmcif=False,\n",
        "        )\n",
        "assert len(target_chains) <= len(\n",
        "      template_chains\n",
        "), f\"Not enough chains in the template structure to cover all target chains. Partial templates are currently not supported on the colab version of AF_unmasked.\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "B3klWdDc79EL"
      },
      "id": "B3klWdDc79EL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "DO1X9PpZ18UJ",
      "metadata": {
        "cellView": "form",
        "id": "DO1X9PpZ18UJ"
      },
      "outputs": [],
      "source": [
        "#@title Step 3: Set other parameters\n",
        "model_type = \"alphafold2_multimer_v2\" #@param [\"alphafold2_multimer_v2\", \"alphafold2_multimer_v3\"]\n",
        "\n",
        "predictions_per_model = 1 #@param {type:\"integer\"}\n",
        "num_recycles = 20 #@param {type:\"integer\"}\n",
        "recycle_early_stop_tolerance = 0.5 #@param {type:\"number\"}\n",
        "use_dropout = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown #### MSA settings\n",
        "msa_mode = \"mmseqs2_uniref\" #@param [\"no_MSA\", \"mmseqs2_uniref\", \"mmseqs2_uniref_env\"]\n",
        "\n",
        "#@markdown -  decrease `msa_depth` to rely more on template information (min: 1)\n",
        "msa_depth = 256 #@param {type:\"integer\"}\n",
        "#@markdown - Pairing of MSAs is currently not allowed to enforce template contraints\n",
        "\n",
        "if msa_depth == \"auto\": msa_depth = None\n",
        "\n",
        "#@markdown Template options\n",
        "inpaint_clashes = True #@param {type:\"boolean\"}\n",
        "align = True #@param {type:\"boolean\"}\n",
        "#superimpose = False #@param {type:\"boolean\"}\n",
        "align_tool = \"blast\"\n",
        "\n",
        "#@markdown #### Save settings\n",
        "save_to_google_drive = False #@param {type:\"boolean\"}\n",
        "\n",
        "if save_to_google_drive:\n",
        "  from pydrive2.drive import GoogleDrive\n",
        "  from pydrive2.auth import GoogleAuth\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  print(\"You are logged into Google Drive and are good to go!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sU_Zn7VgPhLP",
      "metadata": {
        "cellView": "form",
        "id": "sU_Zn7VgPhLP"
      },
      "outputs": [],
      "source": [
        "#@title Step 4: provide mapping between target sequences and template chains\n",
        "\n",
        "template_preview = [f\"Chain {template_chain} (seq: {template_seq[:10]}...)\" for template_chain, template_seq in zip(template_chains, template_sequences)]\n",
        "template_c = [widgets.Dropdown(options=template_preview, value=template_preview[i]) for i, ch in enumerate(target_chains)]\n",
        "\n",
        "for i, widget in enumerate(template_c):\n",
        "  print(f\"Select template chain for fasta sequence {i+1} (seq: {target_sequences[i][:10]}...)\")\n",
        "  display(widget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7678a19-f438-4752-87da-1257526ab1c9",
      "metadata": {
        "cellView": "form",
        "id": "e7678a19-f438-4752-87da-1257526ab1c9"
      },
      "outputs": [],
      "source": [
        "#@title Step 5: Perform sequence-template alignments and check the results\n",
        "#@markdown - Make sure to double check the alignments in the output to see that they are correct\n",
        "#@markdown - Run this cell up to 4 times to fill all the template slots in AlphaFold\n",
        "\n",
        "repeat_template = \"4 times\" #@param [\"1 time\", \"2 times\", \"3 times\", \"4 times\"]\n",
        "\n",
        "temp_reps = int(repeat_template.split()[0])\n",
        "template_chains = [temp.value.split()[1] for temp in template_c]\n",
        "\n",
        "if len(template_chains) != len(set(template_chains)):\n",
        "  raise ValueError(\"Must select a different template chain for each fasta sequence\")\n",
        "\n",
        "append = False\n",
        "\n",
        "mmcif_path = Path(out_dir, \"template_data\", \"mmcif_files\")\n",
        "mmcif_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for i in range(temp_reps):\n",
        "    print(f\"Filling template slot n. {i+1}...\")\n",
        "    next_id = get_next_id(mmcif_path) if append else \"0000\"\n",
        "\n",
        "    io = MMCIFIO()\n",
        "    template_mmcif_path = os.path.join(\n",
        "        out_dir, \"template_data\", \"mmcif_files\", f\"{next_id}.cif\"\n",
        "    )\n",
        "\n",
        "    if inpaint_clashes:\n",
        "        template_model = detect_and_remove_clashes(template_model)\n",
        "        template_sequences = [\n",
        "            get_fastaseq(template_model, chain) for chain in template_chains\n",
        "        ]\n",
        "\n",
        "    io.set_structure(template_model)\n",
        "    io.save(template_mmcif_path)\n",
        "\n",
        "    fix_mmcif(\n",
        "        template_mmcif_path, template_chains, template_sequences, \"2100-01-01\"\n",
        "    )\n",
        "\n",
        "    pdb_seqres_path = Path(out_dir, \"template_data\", \"pdb_seqres.txt\").resolve()\n",
        "    write_seqres(\n",
        "        pdb_seqres_path,\n",
        "        template_sequences,\n",
        "        template_chains,\n",
        "        seq_id=next_id,\n",
        "        append=append,\n",
        "    )\n",
        "\n",
        "    # extra flagfile for AF usage\n",
        "    af_flagfile_path = Path(out_dir, \"template_data\", \"templates.flag\")\n",
        "    if not af_flagfile_path.is_file():  # don't overwrite file if already there\n",
        "        with open(af_flagfile_path, \"w\") as flagfile:\n",
        "            flagfile.write(f\"--template_mmcif_dir={mmcif_path.resolve()}\\n\")\n",
        "            flagfile.write(f\"--pdb_seqres_database_path={pdb_seqres_path}\\n\")\n",
        "            if align:  # means we are not going to let AF overwrite pdb_hits.sto\n",
        "                flagfile.write(\"--use_precomputed_msas\\n\")\n",
        "\n",
        "    if align:\n",
        "\n",
        "        assert len(target_chains) == len(\n",
        "            template_chains\n",
        "        ), f\"The number of chains to align from target ({target_chains}) doesn't match the number of chains in the template ({template_chains}). Make sure that the files contain the same number of chains or select the chains that should be paired with --target_chains, --template_chains\"\n",
        "        for (\n",
        "            i,\n",
        "            (\n",
        "                template_chain,\n",
        "                template_sequence,\n",
        "                target_chain,\n",
        "                target_sequence,\n",
        "                target_model,\n",
        "            ),\n",
        "        ) in enumerate(\n",
        "            zip(\n",
        "                template_chains,\n",
        "                template_sequences,\n",
        "                target_chains,\n",
        "                target_sequences,\n",
        "                target_models,\n",
        "            )\n",
        "        ):\n",
        "            msa_chain = ascii_upperlower[i]\n",
        "            this_template_model = pickle.loads(pickle.dumps(template_model, -1))\n",
        "            this_target_model = pickle.loads(pickle.dumps(target_model, -1))\n",
        "            print(f\"Aligning fasta sequence {i+1} (seq: {target_sequence[0:10]}...) to template chain {template_chain} (seq: {template_sequence[0:10]}...)\")\n",
        "            alignment = do_align(\n",
        "                template_sequence,\n",
        "                this_template_model,\n",
        "                target_sequence,\n",
        "                this_target_model,\n",
        "                alignment_type=\"blast\",\n",
        "            )\n",
        "            sto_alignment = format_alignment_stockholm(\n",
        "                alignment, hit_id=next_id, hit_chain=template_chain\n",
        "            )\n",
        "\n",
        "\n",
        "            msa_path = f\"msas/{msa_chain}\"\n",
        "\n",
        "            # write alignment to file\n",
        "            Path(out_dir, msa_path).mkdir(parents=True, exist_ok=True)\n",
        "            with open(\n",
        "                Path(out_dir, msa_path, \"pdb_hits.sto\"),\n",
        "                mode=\"a\" if append else \"w\",\n",
        "            ) as pdb_hits:\n",
        "                for line in sto_alignment:\n",
        "                    pdb_hits.write(line)\n",
        "    if temp_reps > 1:\n",
        "        append = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d2a63c8-7e34-4f45-88aa-675355cf1818",
      "metadata": {
        "id": "5d2a63c8-7e34-4f45-88aa-675355cf1818",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Step 6: Run the prediction with AF_unmasked\n",
        "\n",
        "if msa_mode == \"no_MSA\": # same as \"no_MSA\" on the AF_unmasked paper\n",
        "  unpaired_msa = []\n",
        "  for i, ts in enumerate(target_sequences):\n",
        "    unpaired_msa.append(f\"> seq_{i}\\n{ts}\")\n",
        "else: # Alignments rely on ColabFold's MSA server\n",
        "  print(\"Querying ColabFold's MSA server\")\n",
        "  msa_lines = None\n",
        "  use_templates = False\n",
        "  custom_template_path = None\n",
        "  pair_mode = \"unpaired\"\n",
        "  pairing_strategy = \"greedy\"\n",
        "  host_url = DEFAULT_API_SERVER\n",
        "  version = importlib_metadata.version(\"colabfold\")\n",
        "  commit = get_commit()\n",
        "  if commit:\n",
        "      version += f\" ({commit})\"\n",
        "  user_agent = f\"colabfold/{version}\"\n",
        "\n",
        "  unpaired_msa, paired_msa, query_seqs_unique, query_seqs_cardinality, template_features = get_msa_and_templates(jobname, target_sequences, msa_lines, out_dir, msa_mode, use_templates,\n",
        "                          custom_template_path, pair_mode, pairing_strategy, host_url, user_agent)\n",
        "\n",
        "for sequence, msa in zip(query_seqs_unique, unpaired_msa):\n",
        "  chains = seq2chain[sequence]\n",
        "  for chain in chains:\n",
        "    out_dir.joinpath(f\"msas/{chain}/bfd_uniref_hits.a3m\").write_text(msa)\n",
        "    pseudo_uniprot = open(out_dir.joinpath(f\"msas/{chain}/uniprot_hits.a3m\"), \"w\")\n",
        "    pseudo_uniprot.write(f\"> {chain}\\n\")\n",
        "    pseudo_uniprot.write(str(sequence))\n",
        "    pseudo_uniprot.close()\n",
        "\n",
        "    input_handle  = open(out_dir.joinpath(f\"msas/{chain}/uniprot_hits.a3m\"), \"r\")\n",
        "    output_handle = open(out_dir.joinpath(f\"msas/{chain}/uniprot_hits.sto\"), \"w\")\n",
        "\n",
        "    alignments = AlignIO.parse(input_handle, \"fasta\")\n",
        "    AlignIO.write(alignments, output_handle, \"stockholm\")\n",
        "\n",
        "    output_handle.close()\n",
        "    input_handle.close()\n",
        "\n",
        "data_dir = Path(\"/content\")\n",
        "if not glob.glob(f\"{data_dir}/params/*_finished.txt\"):\n",
        "  print(\"downloading AF parameters...\")\n",
        "  download_alphafold_params(model_type, data_dir)\n",
        "\n",
        "template_searcher = hmmsearch.Hmmsearch(\n",
        "    binary_path=shutil.which(\"hmmsearch\"),\n",
        "    hmmbuild_binary_path=shutil.which(\"hmmbuild\"),\n",
        "    database_path=out_dir.joinpath(f\"template_data/pdb_seqres.txt\"))\n",
        "\n",
        "template_featurizer = templates.HmmsearchHitFeaturizer(\n",
        "    mmcif_dir=mmcif_path.resolve(),\n",
        "    max_template_date=\"2100-01-01\",\n",
        "    max_hits=4,\n",
        "    kalign_binary_path=shutil.which(\"kalign\"),\n",
        "    release_dates_path=None,\n",
        "    obsolete_pdbs_path=None)\n",
        "\n",
        "monomer_data_pipeline = pipeline.DataPipeline(\n",
        "    jackhmmer_binary_path=shutil.which(\"jackhmmer\"),\n",
        "    hhblits_binary_path=shutil.which(\"hhblits\"),\n",
        "    uniref90_database_path=\".\",\n",
        "    mgnify_database_path=\"\",\n",
        "    bfd_database_path=\"\",\n",
        "    uniref30_database_path=\"\",\n",
        "    small_bfd_database_path=\"\",\n",
        "    template_searcher=template_searcher,\n",
        "    template_featurizer=template_featurizer,\n",
        "    use_small_bfd=False,\n",
        "    use_precomputed_msas=True,\n",
        "    mgnify_max_hits=1,\n",
        "    uniref_max_hits=1,\n",
        "    bfd_max_hits=msa_depth,\n",
        "    no_uniref=True,\n",
        "    no_mgnify=True)\n",
        "\n",
        "data_pipeline = pipeline_multimer.DataPipeline(\n",
        "    monomer_data_pipeline=monomer_data_pipeline,\n",
        "    jackhmmer_binary_path=shutil.which(\"jackhmmer\"),\n",
        "    uniprot_database_path=None,\n",
        "    use_precomputed_msas=True,\n",
        "    max_uniprot_hits=1,\n",
        "    separate_homomer_msas=True)\n",
        "\n",
        "model_names = [\"model_5_multimer_v2\"] if model_type == \"alphafold2_multimer_v2\" else [\"model_5_multimer_v3\"]\n",
        "\n",
        "model_runners = {}\n",
        "\n",
        "for model_name in model_names:\n",
        "    model_config = config.model_config(model_name)\n",
        "    model_config.model.num_ensemble_eval = 1\n",
        "    model_config.model.embeddings_and_evoformer.cross_chain_templates = True\n",
        "    model_config.model.num_recycle = num_recycles\n",
        "    model_config.model.global_config.eval_dropout = use_dropout\n",
        "    model_config.model.recycle_early_stop_tolerance = recycle_early_stop_tolerance\n",
        "\n",
        "    model_params = data.get_model_haiku_params(\n",
        "        model_name=model_name, data_dir=str(data_dir))\n",
        "    model_runner = model.RunModel(model_config, model_params)\n",
        "    for i in range(predictions_per_model):\n",
        "      model_runners[f'{model_name}_pred_{i}'] = model_runner\n",
        "\n",
        "predict_structure(\n",
        "    fasta_path=targets,\n",
        "    fasta_name=jobname,\n",
        "    output_dir_base=\"/content\",\n",
        "    data_pipeline=data_pipeline,\n",
        "    model_runners=model_runners,\n",
        "    benchmark=False,\n",
        "    random_seed=0,\n",
        "    models_to_relax=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compare predictions to the template\n",
        "import py3Dmol\n",
        "import matplotlib.pyplot as plt\n",
        "from colabfold.colabfold import plot_plddt_legend\n",
        "from colabfold.colabfold import pymol_color_list, alphabet_list\n",
        "\n",
        "rank_num = 0 #@param [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"] {type:\"raw\"}\n",
        "color = \"chain\" #@param [\"chain\", \"lDDT\", \"rainbow\"]\n",
        "show_sidechains = False #@param {type:\"boolean\"}\n",
        "show_mainchains = False #@param {type:\"boolean\"}\n",
        "\n",
        "def show_pdb(pdb_file, extension, show_sidechains=False, show_mainchains=False, color=\"lDDT\"):\n",
        "  view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js',)\n",
        "  view.addModel(open(pdb_file,'r').read(), extension)\n",
        "\n",
        "  if color == \"lDDT\":\n",
        "    view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':50,'max':90}}})\n",
        "  elif color == \"rainbow\":\n",
        "    view.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "  elif color == \"chain\":\n",
        "    chains = len(target_sequences) + 1\n",
        "    for n,chain,color in zip(range(chains),alphabet_list,pymol_color_list):\n",
        "       view.setStyle({'chain':chain},{'cartoon': {'color':color}})\n",
        "\n",
        "  if show_sidechains:\n",
        "    BB = ['C','O','N']\n",
        "    view.addStyle({'and':[{'resn':[\"GLY\",\"PRO\"],'invert':True},{'atom':BB,'invert':True}]},\n",
        "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
        "                        {'sphere':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
        "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "  if show_mainchains:\n",
        "    BB = ['C','O','N','CA']\n",
        "    view.addStyle({'atom':BB},{'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "\n",
        "  view.zoomTo()\n",
        "  return view\n",
        "\n",
        "prediction_pdb = f\"{out_dir}/ranked_{rank_num}.pdb\"\n",
        "template_pdb = f\"{mmcif_path}/0000.cif\"\n",
        "\n",
        "print(\"Template\")\n",
        "show_pdb(template_pdb, \"cif\", show_sidechains, show_mainchains, color).show()\n",
        "print(\"Prediction\")\n",
        "show_pdb(prediction_pdb, \"pdb\", show_sidechains, show_mainchains, color).show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "M8nHfehVTCz4"
      },
      "id": "M8nHfehVTCz4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eJt5jHOI39Am",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "eJt5jHOI39Am",
        "outputId": "23224deb-8b48-48ff-8766-14831973eeb4"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_58e973e0-691e-4c6d-970d-115d49140efd\", \"H1142_AF_unmasked.zip\", 2245958)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Download results\n",
        "exclude_pickles = True #@param {type:\"boolean\"}\n",
        "extra_zip_flags = \"-x '*.pkl'\" if exclude_pickles else \"\"\n",
        "results_zip = f\"{jobname}_AF_unmasked.zip\"\n",
        "os.system(f\"zip {extra_zip_flags} -r {results_zip} {jobname}\")\n",
        "\n",
        "files.download(f\"{jobname}_AF_unmasked.zip\")\n",
        "if save_to_google_drive == True and drive:\n",
        "  uploaded = drive.CreateFile({'title': f\"{jobname}_AF_unmasked.zip\"})\n",
        "  uploaded.SetContentFile(f\"{jobname}_AF_unmasked.zip\")\n",
        "  uploaded.Upload()\n",
        "  print(f\"Uploaded {jobname}_AF_unmasked.zip to Google Drive with ID {uploaded.get('id')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FeuGHFIYLifJ",
      "metadata": {
        "cellView": "form",
        "id": "FeuGHFIYLifJ"
      },
      "outputs": [],
      "source": [
        "#@title References\n",
        "\n",
        "\"\"\"\n",
        "@article{af_unmasked,\n",
        "  title={Unmasking AlphaFold: integration of experiments and predictions in multimeric complexes},\n",
        "  author={Mirabello, Claudio and Wallner, Bj{\\\"o}rn and Nystedt, Bj{\\\"o}rn and Azinas, Stavros and Carroni, Marta},\n",
        "  journal={bioRxiv},\n",
        "  pages={2023--09},\n",
        "  year={2023},\n",
        "  publisher={Cold Spring Harbor Laboratory}\n",
        "}\n",
        "\n",
        "@article{af2,\n",
        "  title={Highly accurate protein structure prediction with {AlphaFold}},\n",
        "  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\\v{Z}}{\\'\\i}dek, Augustin and Potapenko, Anna and others},\n",
        "  journal={Nature},\n",
        "  volume={596},\n",
        "  number={7873},\n",
        "  pages={583--589},\n",
        "  year={2021},\n",
        "  publisher={Nature Publishing Group UK London}\n",
        "}\n",
        "\n",
        "@article{af2_multimer,\n",
        "  title={Protein complex prediction with {AlphaFold-Multimer}},\n",
        "  author={Evans, Richard and Oâ€™Neill, Michael and Pritzel, Alexander and Antropova, Natasha and Senior, Andrew and Green, Tim and {\\v{Z}}{\\'\\i}dek, Augustin and Bates, Russ and Blackwell, Sam and Yim, Jason and others},\n",
        "  journal={BioRxiv},\n",
        "  pages={2021--10},\n",
        "  year={2021},\n",
        "  publisher={Cold Spring Harbor Laboratory}\n",
        "}\n",
        "\n",
        "@article{colabfold,\n",
        "  title={ColabFold: making protein folding accessible to all},\n",
        "  author={Mirdita, Milot and Sch{\\\"u}tze, Konstantin and Moriwaki, Yoshitaka and Heo, Lim and Ovchinnikov, Sergey and Steinegger, Martin},\n",
        "  journal={Nature methods},\n",
        "  volume={19},\n",
        "  number={6},\n",
        "  pages={679--682},\n",
        "  year={2022},\n",
        "  publisher={Nature Publishing Group US New York}\n",
        "}\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}